{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8394a925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sharhad/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "# from googletrans import Translator\n",
    "from cleantext import clean\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7e094f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input is csv\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, \n",
    "                 excel_filename = 'VMR Python Data TEST Sep\\'22.xlsx', \n",
    "                 csv_filename = 'movies.csv',\n",
    "                 train = True,\n",
    "                 convert = False, \n",
    "                 translate = False, \n",
    "                 stem = False, \n",
    "                 lemm = True):\n",
    "        if convert: self.convert_to_csv(csv_filename = csv_filename, \n",
    "                                        excel_filename = excel_filename,\n",
    "                                        train = train)\n",
    "        df = self.read_csv(filename = csv_filename)\n",
    "        df = self.clean_data(df, translate = False, stem = False, lemm = True, train = train)\n",
    "        self.save_df(df, filename = csv_filename)\n",
    "        \n",
    "    def convert_to_csv(self, csv_filename = 'movies.csv', \n",
    "                       excel_filename = 'VMR Python Data TEST Sep\\'22.xlsx',\n",
    "                       train = True):\n",
    "        header = ['name']\n",
    "        if train:\n",
    "            header = ['name', 'class']\n",
    "        df = pd.DataFrame(pd.read_excel(excel_filename))\n",
    "        df.to_csv(csv_filename, index = None, header = header)\n",
    "\n",
    "    def read_csv(self, filename = 'movies.csv'):\n",
    "        return pd.read_csv(filename)\n",
    "\n",
    "    def clean_data(self, df, translate = False, stem = False, lemm = True, train = True):\n",
    "#         translator = Translator()\n",
    "        stop = stopwords.words('english')\n",
    "        stemmer = PorterStemmer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        df['name'] = df['name'].str.replace('[^A-Za-z0-9 ]+', ' ')\n",
    "        if translate: \n",
    "            df['name'] = df['name'].apply(lambda x: translator.translate(x, dest = 'en'))\n",
    "        df['name'] = df['name'].apply(lambda x: clean(x))\n",
    "        df['name'] = df['name'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "        if stem:\n",
    "            df['name'] = df['name'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "        if lemm:\n",
    "            df['name'] = df['name'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "\n",
    "        if train:\n",
    "            df['class'] = df['class'].map({'Entertainment': 0, 'News': 1, 'Sports': 2})\n",
    "        df = df.dropna()\n",
    "        return df\n",
    "\n",
    "    def save_df(self, df, filename = 'movies.csv'):\n",
    "        df.to_csv(filename, index = None)\n",
    "        print('Data has been cleaned and saved at {}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52fe5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self, \n",
    "                 csv_filename = 'movies.csv',\n",
    "                 excel_filename = 'VMR Python Data TEST Sep\\'22.xlsx',\n",
    "                 delete_csv = False,\n",
    "                 delete_excel = False,\n",
    "                 model_filename = 'model.pkl'):\n",
    "        self.train(csv_filename = 'movies.csv', model_filename = 'model.pkl')\n",
    "        if delete_csv:\n",
    "            os.remove(csv_filename)\n",
    "        if delete_excel:\n",
    "            os.remove(excel_filename)\n",
    "        \n",
    "    def get_data(self, \n",
    "                 excel_filename = 'VMR Python Data TEST Sep\\'22.xlsx',\n",
    "                 csv_filename = 'movies.csv'):\n",
    "        Data(excel_filename = 'VMR Python Data TEST Sep\\'22.xlsx', \n",
    "             csv_filename = 'movies.csv',\n",
    "            convert = True)\n",
    "        df = shuffle(pd.read_csv(csv_filename).dropna())\n",
    "        X = df['name']\n",
    "        y = df['class']\n",
    "        return X, y\n",
    "    \n",
    "    def train(self, csv_filename = 'movies.csv', model_filename = 'model.pkl'):\n",
    "        X, y = self.get_data(csv_filename = csv_filename)\n",
    "        movie_clf = Pipeline([\n",
    "             ('vect', CountVectorizer(stop_words = 'english')),\n",
    "             ('tfidf', TfidfTransformer()),\n",
    "             ('clf', LogisticRegression(C = 100.0, random_state = 1, solver = 'lbfgs', multi_class = 'ovr'))\n",
    "        ])\n",
    "        model = movie_clf.fit(X, y)\n",
    "        pickle.dump(model, open(model_filename, 'wb'))\n",
    "        print('Model saved at {}'.format(model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e0c6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predict:\n",
    "    def __init__(self, \n",
    "                 csv_filename = 'movies.csv',\n",
    "                 out_filename = 'movies_predict.csv',\n",
    "                 excel_filename = 'VMR Python Data TEST Sep\\'22_predict.xlsx',\n",
    "                 model_filename = 'model.pkl',\n",
    "                 delete_csv = False,\n",
    "                 delete_excel = False):\n",
    "        self.predict(csv_filename = 'movies.csv',\n",
    "                     excel_filename = 'VMR Python Data TEST Sep\\'22_predict.xlsx',\n",
    "                     model_filename = 'model.pkl',\n",
    "                     out_filename = 'movies_predict.csv')\n",
    "        if delete_csv:\n",
    "            os.remove(csv_filename)\n",
    "        if delete_excel:\n",
    "            os.remove(excel_filename)\n",
    "        \n",
    "    def get_data(self, \n",
    "                 excel_filename = 'VMR Python Data TEST Sep\\'22_predict.xlsx', \n",
    "                 csv_filename = 'movies.csv'):\n",
    "        Data(excel_filename = 'VMR Python Data TEST Sep\\'22_predict.xlsx', \n",
    "             csv_filename = 'movies.csv', \n",
    "             convert = True, train = False)\n",
    "        df = pd.read_csv(csv_filename).dropna()\n",
    "        X = df['name']\n",
    "        return X\n",
    "    \n",
    "    def predict(self, \n",
    "                csv_filename = 'movies.csv',\n",
    "                excel_filename = 'VMR Python Data TEST Sep\\'22_predict.xlsx',\n",
    "                model_filename = 'model.pkl',\n",
    "                out_filename = 'movies_predict.csv'):\n",
    "        X = self.get_data(csv_filename = 'movies.csv',\n",
    "                 excel_filename = 'VMR Python Data TEST Sep\\'22_predict.xlsx')\n",
    "        model = pickle.load(open(model_filename, 'rb'))\n",
    "        y_predict = model.predict(X)\n",
    "        pd.DataFrame({'name': X, 'class': y_predict}).to_csv(out_filename, index = False)\n",
    "        print('Predictions saved at {}'.format(out_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "549b1955",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been cleaned and saved at movies.csv\n",
      "Predictions saved at movies_predict.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Predict at 0x7fd07a4c64c0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ff28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
